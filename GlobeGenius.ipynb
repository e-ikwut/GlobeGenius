{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TBY7BDbrTGB",
        "outputId": "2b1a5f50-3f00-4291-d99e-9336d340834f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_data_dir = '/content/drive/My Drive/CS 229/StreetViewImages/'\n",
        "local_data_dir = '/content/StreetViewImages'\n",
        "\n",
        "if not os.path.exists(local_data_dir):\n",
        "    shutil.copytree(drive_data_dir, local_data_dir)\n",
        "    print(\"Dataset copied\")\n",
        "else:\n",
        "    print(\"Dataset already exists\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2zKG-wS8aZR4",
        "outputId": "fb972b43-f481-4a98-d8d1-cee595fc8d57"
      },
      "outputs": [],
      "source": [
        "# VIT\n",
        "import os\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from tqdm import tqdm\n",
        "from torchvision.transforms.v2 import RandomErasing, TrivialAugmentWide\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "local_data_dir = \"/content/StreetViewImages\"\n",
        "\n",
        "\n",
        "def split_train_test(dataset):\n",
        "  count = 0\n",
        "  train_indices = []\n",
        "  test_indices = []\n",
        "  for idx, (img_path, label) in enumerate(dataset.imgs):\n",
        "      img_name = os.path.basename(img_path)\n",
        "      img_number = int(img_name.split(\".\")[0])\n",
        "      if img_number < 4050:\n",
        "          train_indices.append(idx)\n",
        "      else:\n",
        "          test_indices.append(idx)\n",
        "      count += 1\n",
        "  print(count)\n",
        "\n",
        "  return Subset(dataset, train_indices), Subset(dataset, test_indices)\n",
        "\n",
        "def compute_mean_std(dataset, batch_size=32, num_workers=2):\n",
        "  loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "  mean = torch.zeros(3)\n",
        "  std = torch.zeros(3)\n",
        "  nb_samples = 0\n",
        "  for images, _ in loader:\n",
        "      batch_samples = images.size(0)\n",
        "      images = images.view(batch_samples, images.size(1), -1)\n",
        "      mean += images.mean(2).sum(0)\n",
        "      std += images.std(2).sum(0)\n",
        "      nb_samples += batch_samples\n",
        "  mean /= nb_samples\n",
        "  std /= nb_samples\n",
        "  return mean.tolist(), std.tolist()\n",
        "\n",
        "\n",
        "temp_dataset = datasets.ImageFolder(root=local_data_dir, transform=transforms.ToTensor())\n",
        "train_dataset_stats, _ = split_train_test(temp_dataset)\n",
        "computed_mean, computed_std = compute_mean_std(train_dataset_stats)\n",
        "print(\"Dataset Mean:\", computed_mean)\n",
        "print(\"Dataset Std:\", computed_std)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((518,518)), # For B16, need 224\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(518, scale=(0.8, 1.0)), # For B16, need 224\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomGrayscale(p=0.1),\n",
        "    transforms.GaussianBlur(kernel_size=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=computed_mean, std=computed_std)\n",
        "])\n",
        "\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((518,518)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=computed_mean, std=computed_std)\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(root=local_data_dir)\n",
        "train_dataset, test_dataset = split_train_test(dataset)\n",
        "\n",
        "train_dataset.dataset.transform = train_transform\n",
        "test_dataset.dataset.transform = test_transform\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "base_model = models.vit_h_14(weights=models.ViT_H_14_Weights.IMAGENET1K_SWAG_E2E_V1)\n",
        "in_features = base_model.heads.head.in_features\n",
        "base_model.heads.head = nn.Linear(in_features, 6)\n",
        "model = base_model\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.encoder.layers[-3:].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001, weight_decay=5e-3)\n",
        "\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\n",
        "\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        image_no = 0\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            image_no += labels.size(0)\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"Test Accuracy: {evaluate_model(model, test_loader):.2f}%\")\n",
        "        plot_confusion_matrix(model, test_loader, dataset.classes)\n",
        "\n",
        "        scheduler.step(running_loss/len(train_loader))\n",
        "\n",
        "\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "def get_all_preds(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    return all_labels, all_preds\n",
        "\n",
        "def plot_confusion_matrix(model, loader, classes):\n",
        "    true_labels, pred_labels = get_all_preds(model, loader)\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "    cm_percent = np.zeros_like(cm, dtype=float)\n",
        "    for i, row in enumerate(cm):\n",
        "        row_sum = row.sum()\n",
        "        if row_sum > 0:\n",
        "            cm_percent[i] = row / row_sum * 100\n",
        "        else:\n",
        "            cm_percent[i] = 0\n",
        "\n",
        "    annot = np.empty_like(cm).astype(str)\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            annot[i, j] = f\"{cm[i, j]}\\n({cm_percent[i, j]:.1f}%)\"\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=annot, fmt=\"\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=5)\n",
        "plot_confusion_matrix(model, test_loader, dataset.classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lUBoyBUkQgC"
      },
      "outputs": [],
      "source": [
        "# LOGISTIC REGRESSION\n",
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "local_data_dir = \"/content/StreetViewImages\"\n",
        "\n",
        "\n",
        "temp_dataset = datasets.ImageFolder(root=local_data_dir, transform=transforms.ToTensor())\n",
        "\n",
        "def split_train_test(dataset):\n",
        "    train_indices = []\n",
        "    test_indices = []\n",
        "    for idx, (img_path, label) in enumerate(dataset.imgs):\n",
        "        img_name = os.path.basename(img_path)\n",
        "        img_number = int(img_name.split(\".\")[0])\n",
        "        if img_number < 4050:\n",
        "            train_indices.append(idx)\n",
        "        else:\n",
        "            test_indices.append(idx)\n",
        "    return Subset(dataset, train_indices), Subset(dataset, test_indices)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(root=local_data_dir)\n",
        "train_dataset, test_dataset = split_train_test(dataset)\n",
        "\n",
        "\n",
        "train_dataset.dataset.transform = train_transform\n",
        "test_dataset.dataset.transform = test_transform\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "num_classes = len(dataset.classes)\n",
        "input_dim = 3 * 224 * 224\n",
        "\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        logits = self.linear(x)\n",
        "        return logits\n",
        "\n",
        "model = LogisticRegressionModel(input_dim, num_classes)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, epochs=30):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"Test Accuracy: {evaluate_model(model, test_loader):.2f}%\")\n",
        "\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_model(model, train_loader, test_loader, criterion, optimizer, epochs=30)\n",
        "    final_acc = evaluate_model(model, test_loader)\n",
        "    print(f\"Test Accuracy: {final_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atgzz2GTl-Di",
        "outputId": "ee501469-1571-4c7b-e45e-db6247aae19a"
      },
      "outputs": [],
      "source": [
        "# RESNET50\n",
        "import os\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from tqdm import tqdm\n",
        "\n",
        "local_data_dir = \"/content/StreetViewImages\"\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "def split_train_test(dataset):\n",
        "    train_indices = []\n",
        "    test_indices = []\n",
        "\n",
        "    for idx, (img_path, label) in enumerate(dataset.imgs):\n",
        "        img_name = os.path.basename(img_path)\n",
        "        img_number = int(img_name.split(\".\")[0])\n",
        "        if img_number < 4050:\n",
        "            train_indices.append(idx)\n",
        "        else:\n",
        "            test_indices.append(idx)\n",
        "\n",
        "    return Subset(dataset, train_indices), Subset(dataset, test_indices)\n",
        "\n",
        "dataset = datasets.ImageFolder(root=local_data_dir, transform=transform)\n",
        "train_dataset, test_dataset = split_train_test(dataset)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 6)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "for param in list(model.parameters())[-11]:\n",
        "    param.requires_grad = True\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001)\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
        "    for module in model.modules():\n",
        "      if isinstance(module, nn.BatchNorm2d):\n",
        "        module.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        image_no = 0\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            image_no += labels.size(0)\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"Test Accuracy: {evaluate_model(model, test_loader):.2f}%\")\n",
        "\n",
        "\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "\n",
        "train_model(model, train_loader, criterion, optimizer, epochs=10)\n",
        "\n",
        "\n",
        "final_acc = evaluate_model(model, test_loader)\n",
        "train_acc = evaluate_model(model, train_loader)\n",
        "print(f\"Test Accuracy: {final_acc:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
